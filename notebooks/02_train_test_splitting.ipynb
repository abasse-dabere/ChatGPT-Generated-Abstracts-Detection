{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fd5341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "795e1b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a643ed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label dictionary â†’ path to the JSONL\n",
    "raw_data_path = '../data/raw/'\n",
    "files = {\n",
    "    'human': f'{raw_data_path}ieee-init.jsonl',\n",
    "    'generation': f'{raw_data_path}ieee-chatgpt-generation.jsonl',\n",
    "    'polish': f'{raw_data_path}ieee-chatgpt-polish.jsonl',\n",
    "    'mix': f'{raw_data_path}ieee-chatgpt-fusion.jsonl'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d5de9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>keyword</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8600003</td>\n",
       "      <td>An Improved Variable-Node-Based BP Decoding Al...</td>\n",
       "      <td>\"Flash memories\",\"Reliability\",\"Decoding\",\"Par...</td>\n",
       "      <td>To solve the problems of the data reliability ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8600004</td>\n",
       "      <td>Mobile Robot Location Algorithm Based on Impro...</td>\n",
       "      <td>\"Sociology\",\"Statistics\",\"Simultaneous localiz...</td>\n",
       "      <td>To solve the simultaneous localization and map...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8600008</td>\n",
       "      <td>Vertical Handoff Decision Algorithm for Hetero...</td>\n",
       "      <td>\"Entropy\",\"Handover\",\"Wireless networks\",\"Deci...</td>\n",
       "      <td>In the future scenario of multiple wireless ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8600013</td>\n",
       "      <td>Robust offline trained neural network for TDOA...</td>\n",
       "      <td>\"Microphones\",\"Artificial neural networks\",\"Po...</td>\n",
       "      <td>Passive sound source localization (SSL) using ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8600014</td>\n",
       "      <td>Gaussian MAC with Feedback and Strictly Causal...</td>\n",
       "      <td>\"Encoding\",\"Transmitters\",\"Decoding\",\"Indexes\"...</td>\n",
       "      <td>We consider a two user Gaussian multiple acces...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              title  \\\n",
       "0  8600003  An Improved Variable-Node-Based BP Decoding Al...   \n",
       "1  8600004  Mobile Robot Location Algorithm Based on Impro...   \n",
       "2  8600008  Vertical Handoff Decision Algorithm for Hetero...   \n",
       "3  8600013  Robust offline trained neural network for TDOA...   \n",
       "4  8600014  Gaussian MAC with Feedback and Strictly Causal...   \n",
       "\n",
       "                                             keyword  \\\n",
       "0  \"Flash memories\",\"Reliability\",\"Decoding\",\"Par...   \n",
       "1  \"Sociology\",\"Statistics\",\"Simultaneous localiz...   \n",
       "2  \"Entropy\",\"Handover\",\"Wireless networks\",\"Deci...   \n",
       "3  \"Microphones\",\"Artificial neural networks\",\"Po...   \n",
       "4  \"Encoding\",\"Transmitters\",\"Decoding\",\"Indexes\"...   \n",
       "\n",
       "                                            abstract  \n",
       "0  To solve the problems of the data reliability ...  \n",
       "1  To solve the simultaneous localization and map...  \n",
       "2  In the future scenario of multiple wireless ne...  \n",
       "3  Passive sound source localization (SSL) using ...  \n",
       "4  We consider a two user Gaussian multiple acces...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human = pd.read_json(files['human'], lines=True)\n",
    "df_human.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a40f687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split parameters\n",
    "split_params = {\n",
    "    'test_size': 0.2,\n",
    "    'random_state': 42,\n",
    "    'shuffle': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc096044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "dfs_train, dfs_test = [], []\n",
    "for label, file in files.items():\n",
    "    # Read the JSONL file\n",
    "    df = pd.read_json(file, lines=True)[['abstract']]\n",
    "    df['label'] = label # Add the label column\n",
    "    # Split the data into train and test sets\n",
    "    df_train, df_test = train_test_split(df, **split_params)\n",
    "    # Save the train and test sets to CSV files\n",
    "    dfs_train.append(df_train)\n",
    "    dfs_test.append(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "172fff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat(dfs_train, ignore_index=True)\n",
    "df_test = pd.concat(dfs_test, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef31dac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the train and test sets to CSV files\n",
    "save_path = '../data/train_test/'\n",
    "df_train.to_csv(f'{save_path}train.csv', index=False)\n",
    "df_test.to_csv(f'{save_path}test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46af5da0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
